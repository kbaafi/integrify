{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalue Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we have a transformation matrix $A$, then we are looking for an vector $v$ such that\n",
    "\n",
    "$A\\vec{v} = \\lambda \\vec{v}$, where $\\lambda$ is a scalar\n",
    "\n",
    "$\\lambda$ is the eigen value and $\\vec{v}$ is the eigen vector\n",
    "\n",
    "Concreteley we are looking for $\\lambda$ such that the transformation matrix $A$ only has a scaling effect, but no rotation effect on $v$\n",
    "\n",
    "so given $A\\vec{v} = \\lambda \\vec{v}$ , if we subtract $A\\vec{v}$ from both sides we get \n",
    "\n",
    "$\\vec{0} = \\lambda\\vec{v} - A\\vec{v}$ and \n",
    "\n",
    "$ \\vec{v} (\\lambda I_n - A) = \\vec{0}$\n",
    "\n",
    "For $(\\lambda I_n - A)$ to be non-trivial $\\vec{v}$ must belong to the nullspace of $(\\lambda I_n - A)$\n",
    "\n",
    "That is to say $\\vec{v} \\subset N(\\lambda I_n - A)$ where $N(x)$ denotes the nullspace\n",
    "\n",
    "**Linearity Property**\n",
    "If a matrix $D$ is non-trivial then it has dependent columns and therefore $D$ is not invertible and $\\mid{D}\\mid = \\vec{0}$\n",
    "\n",
    "From this it follows that $\\mid{\\lambda I_n - A}\\mid = \\vec{0}$\n",
    "\n",
    "So for a transformation matrix $A$ we are looking for a vector $\\vec{v}$ and a scalar $\\lambda$  such that $\\mid{\\lambda I_n - A}\\mid = \\vec{0}$ and $A\\vec{v} = \\lambda \\vec{v}$\n",
    "\n",
    "If we solve for $\\lambda_i$, we have found the eigen values of transformation $A$,\n",
    "\n",
    "we can then solve for the vectors $\\vec{v}_i$ to find the eigen vector of $A$\n",
    "\n",
    "**Pseudocode**\n",
    "\n",
    "Inputs: \n",
    "    $A$\n",
    "    \n",
    "Begin:\n",
    "    \n",
    "solve for  $\\lambda$ from $\\mid{\\lambda I_n - A}\\mid = \\vec{0}$\n",
    "    \n",
    "for each $\\lambda_i$ in $\\lambda$:\n",
    "\n",
    "   find $\\vec{v}$ such that $ \\vec{v} (\\lambda I_n - A) = \\vec{0}$\n",
    "   \n",
    "End:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVD of Covariance Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the covariance matrix $\\mathbf{\\Sigma}$\n",
    "\n",
    "$\\mathbf{\\Sigma} = {\\sum}_i^D\\lambda_i u_i u_i^T$ we can assert that $\\mathbf{\\Sigma}=VDV^{-1}$\n",
    "\n",
    "Since the covariance matrix is symmetric, it has the propterty that all of its eigen vectors are not only independent but also orthogonal\n",
    "\n",
    "Let $A$ be the covariance matrix\n",
    "Let $V = [v_i v_2 ...... v_n]$ be a matrix of eigen vectors placed in the columns\n",
    "Let $D$ be a diagonal matrix where the $ii^{th}$ position, then in accordance to the eigen value problem \n",
    "\n",
    "$AV = VD$\n",
    "$AV = [Av_i, Av_2, ....., Av_n ]$\n",
    "\n",
    "$VD = [\\lambda_1 v_i, \\lambda_1 v_2, ....., \\lambda_n v_n ]$\n",
    "\n",
    "Since $\\mathbf{\\Sigma}$ is symmetric, if we choose any two eigen values, $\\lambda_1 , \\lambda_2$ and corresponding eigen vectors, $v_1, v_2$\n",
    "\n",
    "then $\\lambda_1 v_1 v_2$ = $(\\lambda_1 v_1)^T v_2$\n",
    "\n",
    "$=(A v_1)^T$\n",
    "\n",
    "$=v_1^TA^Tv_2$\n",
    "\n",
    "$=v_1^T(Av_2)$\n",
    "\n",
    "$=v_1^T(\\lambda_2 v_2)$\n",
    "\n",
    "So $\\lambda_1 v_1 v_2$ = $\\lambda_2 v_1 v_2$\n",
    "\n",
    "and it follows that \n",
    "\n",
    "$(\\lambda_1 - \\lambda_2)v_1 . v_2 = 0$\n",
    "\n",
    "Satisfying the condition of no dependence in the columns of a symmetric matrix, therefore we can say that the eigen vectors of a symmetric matrix are orthogonal\n",
    "\n",
    "If $V$ is an orthogonal matrix then it follows that $V^T = V^{-1}$\n",
    "\n",
    "Then the covariance matrix $\\mathbf{\\Sigma}$ which is a symmetric matrix can be diagonalized by a diagonal matrix $D$ and the matrix of eigen vectors $V$ such that\n",
    "\n",
    "$\\mathbf{\\Sigma}$ = $VDV^{-1}$\n",
    "\n",
    "Since $\\mathbf{\\Sigma}^T = \\mathbf{\\Sigma}$\n",
    "\n",
    "$\\mathbf{\\Sigma}^T = (VDV^T)^T = V^{TT}D^TV^T = VDV^T = \\mathbf{\\Sigma}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA using EVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[7., 4., 1., 9., 2., 8., 3., 2., 2., 0., 3., 6., 8., 5., 9., 6.,\n",
       "        9., 3., 7., 3.],\n",
       "       [6., 4., 4., 4., 6., 2., 2., 8., 3., 4., 3., 8., 2., 3., 6., 7.,\n",
       "        0., 9., 2., 3.],\n",
       "       [4., 1., 2., 9., 3., 8., 1., 3., 9., 6., 1., 9., 5., 9., 2., 0.,\n",
       "        1., 1., 2., 1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_matrix = np.random.randint(10,size=(N, 20)).astype(np.float)\n",
    "input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.66666667, 3.        , 2.33333333, 7.33333333, 3.66666667,\n",
       "       6.        , 2.        , 4.33333333, 4.66666667, 3.33333333,\n",
       "       2.33333333, 7.66666667, 5.        , 5.66666667, 5.66666667,\n",
       "       4.33333333, 3.33333333, 4.33333333, 3.66666667, 2.33333333])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mn = input_matrix.mean(axis = 0)\n",
    "mn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.33333333,  1.        , -1.33333333,  1.66666667, -1.66666667,\n",
       "         2.        ,  1.        , -2.33333333, -2.66666667, -3.33333333,\n",
       "         0.66666667, -1.66666667,  3.        , -0.66666667,  3.33333333,\n",
       "         1.66666667,  5.66666667, -1.33333333,  3.33333333,  0.66666667],\n",
       "       [ 0.33333333,  1.        ,  1.66666667, -3.33333333,  2.33333333,\n",
       "        -4.        ,  0.        ,  3.66666667, -1.66666667,  0.66666667,\n",
       "         0.66666667,  0.33333333, -3.        , -2.66666667,  0.33333333,\n",
       "         2.66666667, -3.33333333,  4.66666667, -1.66666667,  0.66666667],\n",
       "       [-1.66666667, -2.        , -0.33333333,  1.66666667, -0.66666667,\n",
       "         2.        , -1.        , -1.33333333,  4.33333333,  2.66666667,\n",
       "        -1.33333333,  1.33333333,  0.        ,  3.33333333, -3.66666667,\n",
       "        -4.33333333, -2.33333333, -3.33333333, -1.66666667, -1.33333333]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whiten the data\n",
    "\n",
    "input_matrix = input_matrix - mn\n",
    "input_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 55.38888889, -28.27777778, -27.11111111],\n",
       "       [-28.27777778,  56.55555556, -28.27777778],\n",
       "       [-27.11111111, -28.27777778,  55.38888889]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov = 1/(N-1)*np.matmul(input_matrix,input_matrix.T)\n",
    "cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.5494152 , -2.95847953, -2.59093567],\n",
       "       [-2.95847953,  5.95204678, -2.99356725],\n",
       "       [-2.59093567, -2.99356725,  5.58450292]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covariance = np.cov(input_matrix)\n",
    "covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 5.77350269e-01,  7.07106781e-01,  4.08248290e-01],\n",
       "        [ 5.77350269e-01,  1.73979692e-15, -8.16496581e-01],\n",
       "        [ 5.77350269e-01, -7.07106781e-01,  4.08248290e-01]]),\n",
       " array([ 0.        , 82.5       , 84.83333333]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas, vs = np.linalg.eig(cov)\n",
    "vectors,values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.57735027,  0.72262852,  0.38009826],\n",
       "        [ 0.57735027, -0.03213951, -0.81586379],\n",
       "        [ 0.57735027, -0.69048901,  0.43576553]]),\n",
       " array([0.        , 8.1566977 , 8.92926721]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambdas, vs = np.linalg.eig(covariance)\n",
    "vectors,values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate ${\\Sigma v = \\lambda v}$\n",
    "\n",
    "${\\Sigma v}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.55431223e-15,  5.89426240e+00,  3.39399892e+00],\n",
       "       [-6.66133815e-16, -2.62152291e-01, -7.28506576e+00],\n",
       "       [ 0.00000000e+00, -5.63211011e+00,  3.89106684e+00]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sigma_v = np.matmul(covariance,vs)\n",
    "sigma_v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ${\\lambda v}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  5.8942624 ,  3.39399892],\n",
       "       [ 0.        , -0.26215229, -7.28506576],\n",
       "       [ 0.        , -5.63211011,  3.89106684]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lambda_v = lambdas*vectors\n",
    "lambda_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

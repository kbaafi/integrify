{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the basic elements of optimization? \n",
    "\n",
    "__Optimization:__\n",
    "    Choosing Inputs that results in best possible output the best they can be.\n",
    "\n",
    "__Basic Elements of Optimization:__\n",
    "\n",
    "__Objective Function:__\n",
    " It is a value we are trying to optimize. \n",
    " \n",
    " __Example:__ \n",
    "\n",
    "Trying to make a square as big as possible the area of the square is __area=a*b__ will be the objective function.\n",
    " The main goal is trying to improve the value of objective function it means minimizing it,maximizing it or trying\n",
    " to bring it to certain value. Looking at the objective function value is one of the common ways to tell how well the optimization has been worked.In case where there are multiple objectives. they are summed (i.e) __objective=a+b__ , multiplied (i.e)__ojective=a*b__ or otherwise combined to form a single value (i.e) __objective=3a+4ab__. In dynamic optimization controk variables also form part of the objective function.It is commonly writtern in the form\n",
    " __minimize f(x)__ ,where f is objective function.The objective function the value that me and my optimization program are trying to optimize the objective function either minimized or maximized.\n",
    " \n",
    " __Decision Variables:__\n",
    " \n",
    " Decision variables are the input to the problem that your optimizer is allowed to cahnge to try to improve the objective function value.\n",
    "\n",
    " __Example:__ \n",
    "As square example above the decision variables would be the length of the two sides (i.e)(a,b) the variables are also called design variables or manipulated variables. As was stated before optimization problems are commonly writtern in form \n",
    "__minimize f(x)__ here x represents one or more decision variables in general the more decision variables in general the more decision variables there are the more difficult an optimization problem becomes to solve \n",
    "(i.e)__minimize f(x1+x2+x3+x4+x5...)__ .Desicion variables are the values that the optimization algorithm is allowed to choose or change.\n",
    " \n",
    " __Constraints__:\n",
    " Contraints defines where the optimizer  cant go or odditional conditions that must be met for a succesfful solution.\n",
    " \n",
    " __Example:__ \n",
    " When optimizing the size of the square we could ass the contraints that the length of two sides (i.e:a,b) multiplied together __a*b<=5__ this is an inequality constraint.We can also add equality constraints __a+b=10__ or __((ab)/(a+b))=3__, other example of constraints might be a bridge with a constraint that it must hold atleast 80,000 pounds or a chemical mixture that must be atleast 99% pure.Optimal solutions tend to be right up against the contraints (i.e) Picture a ball rolling downhill and encountring a wall.Constraints tell the software where it cannot go they often represents physical limitations of a system\n",
    " \n",
    "### Why optimization is important\n",
    "\n",
    "Importance of Optimization in Machine Learning Importance of machine learning depends on the methods and techniques we use in machine learning. Optimization is very important in some methods but not in all the methods. Example: Hastie, Tibshivani and Friedman's elements of satistical learning is considered as the most important reference in machine learning and it has very little reference to optimization. But when it comes to developing efficient and scalable algorithms to solve the machine learning problems, then optimizatoin is very important."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Loss/Cost function\n",
    "\n",
    "Supposing we have a hypothesis function $h(\\mathbf{x}) = \\theta_0 + \\theta_{1}x$ and a set of expected outputs $\\mathbf{y}$ that we think this function will map instances of $x$ to, then the cost function is a function that penalizes our hypothesis for incorrect mappings of the input data $\\mathbf{x}$ to outputs $\\mathbf{y}$. The cost function is important for directing the hypothesis $h(\\mathbf{x})$ to the goal($\\mathbf{y}$). Suppose we choose a least squares error cost function, then our cost function will look like\n",
    "\n",
    "$$J_{\\mathbf{\\Theta}}(x) = \\frac{1}{2m}\\Sigma (h(x)_i - y_i)^2$$\n",
    "\n",
    "Our goal is to minimize $J_{\\mathbf{\\Theta}}(x)$, updating the weights of the hypothesis $\\mathbf{\\Theta}$ at each step, and this should refine our hypothesis such that the parameters of the hypothesis produce an output that closely matches the expected outputs $\\mathbf{y}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the Gradient operator?\n",
    "\n",
    "The gradient operator can be thought of as a generalization of the concept of a slope for multivariable functions. It is a vector that, given a scalar field, points to the directive of the steepest change in the function. Take for example the scalar function f(x,y,z). Its gradient is ∇f=∂f/∂xx^+∂f/∂yy^+∂f/∂zz^\n",
    "\n",
    "We can express the change in the function as df=∇f⋅dr. We see that df is maximum the dr and ∇f are parallel.\n",
    "Gradient operator is the first type of operators used for edge detection. The gradient of an image is a vector consisting of the first-order derivatives (including the magnitude and direction) of an image.The Gradient (also called the Hamilton operator) is a vector operator for any N-dimensional scalar.The gradient operator is a bit similar to the derivative, as it shows the variation of a scalar field in space. For instance, let’s say you are considering a temperature field. Every point in space has its own temperature attached to it. Now the gradient operator associates to each point a vector, based on the variation of the temperature around it. More specifically, if you followed the gradient vector on a really short distance, the temperature would increase by the norm of the vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation between Gradient, Eigen Values, Optimization and Convergence\n",
    "\n",
    "Using an example of the least squares cost function, we hope to optimize a function of the form\n",
    "\n",
    "![eq5](images/eq5.png)\n",
    "\n",
    "which can be written as \n",
    "\n",
    "![eq6](images/eq6.png)\n",
    "\n",
    "The first order derivative can be written as\n",
    "\n",
    "![eq7](images/eq7.png)\n",
    "\n",
    "and for the second order derivative which is also known as the Hessian, \n",
    "\n",
    "![eq8](images/eq8.png)\n",
    "\n",
    "Eigen values represent the change in length of the eigen vector when multiplied with a column matrix of eigen vectors. In the case of the Hessian, the eigen vectors repesent a direction where the curvature is independent of other directions. The larger the eigen value, the larger the curvature and the larger the rate of change in the direction of the eigen vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation between quadratic form, Hessian, Precision matrix and Optimization\n",
    "\n",
    "For a Gaussian random vector $\\mathbf{\\Theta}$ with mean $\\mathbf{\\Theta}^{*}$ and covariance matrix $\\mathbf{\\Sigma_{\\Theta}}$ and its joint PDF is given by\n",
    "\n",
    "![eq1](images/eq1.png)\n",
    "\n",
    "The objective function of the random vector can be defined as \n",
    "\n",
    "![eq2](images/eq2.png)\n",
    "\n",
    "We can see that the objective function of the random Gaussian vector is a quadratic function of the components in $\\mathbf{\\Theta}$. About the mean $\\mathbf{\\Theta}^{*}$, the $(l,l')$ component of the Hessian matrix can be written as:\n",
    "\n",
    "![eq3](images/eq3.png)\n",
    "\n",
    "So for a Gaussian random vector, the Hessian matrix evaluated at the mean is the invserse of the covariance matrix (which is the Precision matrix)\n",
    "\n",
    "### Hessian and Optimization\n",
    "A gradient descent with step size $\\alpha$ can be expressed as:\n",
    "\n",
    "$$x^{t+1} = x^t - \\alpha(Hx^{t} - b)$$\n",
    "\n",
    "Where $H$ is the Hessian matrix\n",
    "\n",
    "In the direction of the $i{th}$ eigen vector,\n",
    "\n",
    "$$x^{t+1} = (1 - \\alpha\\lambda_i)^tx^0$$\n",
    "\n",
    "where $x^0$ is the initial vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Momentum\n",
    "\n",
    "Momentum mitigates the problems associated with the Gradient Descent. Optimization with momentum remembers the update $\\Delta w$ at each iteration and determines the next update as a linear combination of the gradient and the previous update. \n",
    "\n",
    "![eq4](images/eq4.png)\n",
    "\n",
    "Where $w^k$ at step $k$ is the gradient of the loss function. What this allows us to do is to barrel through narrow valleys, small humps and local minima. This leads to faster convergence and higher confidence of reaching the global minimum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
